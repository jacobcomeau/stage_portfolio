{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.OutputArea.prototype._should_scroll = function(lines) {\n    return false;\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from os.path import join, exists, isfile, isdir\n",
    "from os import makedirs, listdir\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 8}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets = [\"breast\", \"ads\", \"adult\", \"farm\", \"mnist17\", \"mnist49\", \"mnist56\"]\n",
    "datasets = [\"ads\"]\n",
    "#experiments = [\"baseline\", \"greedy_kernel\", \"landmarks_based\"]\n",
    "experiments = [\"greedy_kernel\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = join(\".\", \"results\")\n",
    "output_path = join(\".\", \"results\", \"fig\")\n",
    "if not(exists(output_path)): makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dir_results(dir_path):\n",
    "    dir_results = []\n",
    "    for f in [f for f in listdir(dir_path) if (isfile(join(dir_path, f)) and f.endswith(\".pkl\"))]:\n",
    "        with open(join(dir_path, f), 'rb') as in_file:\n",
    "            dir_results += pickle.load(in_file)\n",
    "                \n",
    "    for d in [d for d in listdir(dir_path) if isdir(join(dir_path, d))]:\n",
    "        dir_results += load_dir_results(join(dir_path, d))\n",
    "    \n",
    "    return dir_results\n",
    "\n",
    "def load_results(results_path):\n",
    "    # Loading\n",
    "    results = []\n",
    "    for exp in set(listdir(results_path)).intersection(experiments):\n",
    "        results += load_dir_results(join(results_path, exp))\n",
    "    results = pd.DataFrame(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      breast\n",
      "1      breast\n",
      "2      breast\n",
      "3      breast\n",
      "4      breast\n",
      "        ...  \n",
      "444    breast\n",
      "445    breast\n",
      "446    breast\n",
      "447    breast\n",
      "448    breast\n",
      "Name: dataset, Length: 449, dtype: object\n",
      "  dataset     exp   algo            C  D      N  gamma      beta  \\\n",
      "0     ads  greedy  PBRFF  7224.677570  1  20000  0.001    10.000   \n",
      "1     ads  greedy  PBRFF   605.090164  1  20000  0.001     1.000   \n",
      "2     ads  greedy  PBRFF  5511.285799  1  20000  0.001     0.100   \n",
      "3     ads  greedy  PBRFF  9925.737610  1  20000  0.001     0.010   \n",
      "4     ads  greedy  PBRFF   837.124505  1  20000  0.001  1000.000   \n",
      "5     ads  greedy  PBRFF  8897.470010  1  20000  0.001     0.001   \n",
      "6     ads  greedy  PBRFF  2248.502085  1  20000  0.001   100.000   \n",
      "\n",
      "                    Loss_l                       E_l  nbrD_choisi  maxTry   p  \\\n",
      "0  [[0.22749169200972805]]   [0.0002386254153995136]            1       8  10   \n",
      "1  [[0.22841588234229918]]  [0.00026357920588288507]            1       9  11   \n",
      "2  [[0.22717899859508353]]  [3.8641050070245826e-05]            1       5   2   \n",
      "3    [[0.226902315669289]]   [0.0003386548842165355]            1       8  14   \n",
      "4  [[0.22067553325312386]]   [0.0002139662233373438]            1       8   9   \n",
      "5  [[0.22725865337578852]]  [0.00031363706733121056]            1       6  13   \n",
      "6  [[0.22067553325312386]]   [0.0002139662233373438]            1       3   9   \n",
      "\n",
      "    epsilon  train_error  val_error  test_error        f1  \\\n",
      "0  0.000006     0.126589   0.142276    0.167073  0.908728   \n",
      "1  0.000008     0.124555   0.144309    0.165854  0.909333   \n",
      "2  0.000001     0.127097   0.142276    0.164634  0.909940   \n",
      "3  0.000175     0.127097   0.144309    0.168293  0.908000   \n",
      "4  0.000040     0.872903   0.855691    0.831707  0.000000   \n",
      "5  0.000009     0.127097   0.144309    0.168293  0.908123   \n",
      "6  0.000021     0.872903   0.855691    0.831707  0.000000   \n",
      "\n",
      "                                                time  \n",
      "0  [(sampling, 1225.1355648040771), (loss, 5888.9...  \n",
      "1  [(sampling, 1225.1355648040771), (loss, 5888.9...  \n",
      "2  [(sampling, 1225.1355648040771), (loss, 5888.9...  \n",
      "3  [(sampling, 1225.1355648040771), (loss, 5888.9...  \n",
      "4  [(sampling, 1225.1355648040771), (loss, 5888.9...  \n",
      "5  [(sampling, 1225.1355648040771), (loss, 5888.9...  \n",
      "6  [(sampling, 1225.1355648040771), (loss, 5888.9...  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ads':   dataset     exp   algo            C  D      N  gamma      beta  \\\n",
       " 0     ads  greedy  PBRFF  7224.677570  1  20000  0.001    10.000   \n",
       " 1     ads  greedy  PBRFF   605.090164  1  20000  0.001     1.000   \n",
       " 2     ads  greedy  PBRFF  5511.285799  1  20000  0.001     0.100   \n",
       " 3     ads  greedy  PBRFF  9925.737610  1  20000  0.001     0.010   \n",
       " 4     ads  greedy  PBRFF   837.124505  1  20000  0.001  1000.000   \n",
       " 5     ads  greedy  PBRFF  8897.470010  1  20000  0.001     0.001   \n",
       " 6     ads  greedy  PBRFF  2248.502085  1  20000  0.001   100.000   \n",
       " \n",
       "                     Loss_l                       E_l  nbrD_choisi  maxTry   p  \\\n",
       " 0  [[0.22749169200972805]]   [0.0002386254153995136]            1       8  10   \n",
       " 1  [[0.22841588234229918]]  [0.00026357920588288507]            1       9  11   \n",
       " 2  [[0.22717899859508353]]  [3.8641050070245826e-05]            1       5   2   \n",
       " 3    [[0.226902315669289]]   [0.0003386548842165355]            1       8  14   \n",
       " 4  [[0.22067553325312386]]   [0.0002139662233373438]            1       8   9   \n",
       " 5  [[0.22725865337578852]]  [0.00031363706733121056]            1       6  13   \n",
       " 6  [[0.22067553325312386]]   [0.0002139662233373438]            1       3   9   \n",
       " \n",
       "     epsilon  train_error  val_error  test_error        f1  \\\n",
       " 0  0.000006     0.126589   0.142276    0.167073  0.908728   \n",
       " 1  0.000008     0.124555   0.144309    0.165854  0.909333   \n",
       " 2  0.000001     0.127097   0.142276    0.164634  0.909940   \n",
       " 3  0.000175     0.127097   0.144309    0.168293  0.908000   \n",
       " 4  0.000040     0.872903   0.855691    0.831707  0.000000   \n",
       " 5  0.000009     0.127097   0.144309    0.168293  0.908123   \n",
       " 6  0.000021     0.872903   0.855691    0.831707  0.000000   \n",
       " \n",
       "                                                 time  \n",
       " 0  [(sampling, 1225.1355648040771), (loss, 5888.9...  \n",
       " 1  [(sampling, 1225.1355648040771), (loss, 5888.9...  \n",
       " 2  [(sampling, 1225.1355648040771), (loss, 5888.9...  \n",
       " 3  [(sampling, 1225.1355648040771), (loss, 5888.9...  \n",
       " 4  [(sampling, 1225.1355648040771), (loss, 5888.9...  \n",
       " 5  [(sampling, 1225.1355648040771), (loss, 5888.9...  \n",
       " 6  [(sampling, 1225.1355648040771), (loss, 5888.9...  }"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_file = join(output_path, \"results.pkl\")\n",
    "if not exists(results_file):\n",
    "    results = load_results(results_path)\n",
    "    with open(results_file, 'wb') as out_file:\n",
    "        pickle.dump(results, out_file)\n",
    "        \n",
    "with open(results_file, 'rb') as in_file:\n",
    "    results = pickle.load(in_file)\n",
    "\n",
    "print(results.dataset)\n",
    "results = load_results(results_path)\n",
    "print(results)\n",
    "results_per_dataset = {d:results.loc[results.dataset == d] for d in datasets}\n",
    "\n",
    "results_per_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>exp</th>\n",
       "      <th>algo</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>N</th>\n",
       "      <th>gamma</th>\n",
       "      <th>beta</th>\n",
       "      <th>Loss_l</th>\n",
       "      <th>E_l</th>\n",
       "      <th>nbrD_choisi</th>\n",
       "      <th>maxTry</th>\n",
       "      <th>p</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>train_error</th>\n",
       "      <th>val_error</th>\n",
       "      <th>test_error</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ads</td>\n",
       "      <td>greedy</td>\n",
       "      <td>PBRFF</td>\n",
       "      <td>7224.677570</td>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10.000</td>\n",
       "      <td>[[0.22749169200972805]]</td>\n",
       "      <td>[0.0002386254153995136]</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.126589</td>\n",
       "      <td>0.142276</td>\n",
       "      <td>0.167073</td>\n",
       "      <td>0.908728</td>\n",
       "      <td>[(sampling, 1225.1355648040771), (loss, 5888.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ads</td>\n",
       "      <td>greedy</td>\n",
       "      <td>PBRFF</td>\n",
       "      <td>605.090164</td>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[[0.22841588234229918]]</td>\n",
       "      <td>[0.00026357920588288507]</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.124555</td>\n",
       "      <td>0.144309</td>\n",
       "      <td>0.165854</td>\n",
       "      <td>0.909333</td>\n",
       "      <td>[(sampling, 1225.1355648040771), (loss, 5888.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ads</td>\n",
       "      <td>greedy</td>\n",
       "      <td>PBRFF</td>\n",
       "      <td>5511.285799</td>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.100</td>\n",
       "      <td>[[0.22717899859508353]]</td>\n",
       "      <td>[3.8641050070245826e-05]</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.127097</td>\n",
       "      <td>0.142276</td>\n",
       "      <td>0.164634</td>\n",
       "      <td>0.909940</td>\n",
       "      <td>[(sampling, 1225.1355648040771), (loss, 5888.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ads</td>\n",
       "      <td>greedy</td>\n",
       "      <td>PBRFF</td>\n",
       "      <td>9925.737610</td>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.010</td>\n",
       "      <td>[[0.226902315669289]]</td>\n",
       "      <td>[0.0003386548842165355]</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.127097</td>\n",
       "      <td>0.144309</td>\n",
       "      <td>0.168293</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>[(sampling, 1225.1355648040771), (loss, 5888.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ads</td>\n",
       "      <td>greedy</td>\n",
       "      <td>PBRFF</td>\n",
       "      <td>837.124505</td>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>[[0.22067553325312386]]</td>\n",
       "      <td>[0.0002139662233373438]</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.872903</td>\n",
       "      <td>0.855691</td>\n",
       "      <td>0.831707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(sampling, 1225.1355648040771), (loss, 5888.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ads</td>\n",
       "      <td>greedy</td>\n",
       "      <td>PBRFF</td>\n",
       "      <td>8897.470010</td>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[[0.22725865337578852]]</td>\n",
       "      <td>[0.00031363706733121056]</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.127097</td>\n",
       "      <td>0.144309</td>\n",
       "      <td>0.168293</td>\n",
       "      <td>0.908123</td>\n",
       "      <td>[(sampling, 1225.1355648040771), (loss, 5888.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ads</td>\n",
       "      <td>greedy</td>\n",
       "      <td>PBRFF</td>\n",
       "      <td>2248.502085</td>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100.000</td>\n",
       "      <td>[[0.22067553325312386]]</td>\n",
       "      <td>[0.0002139662233373438]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.872903</td>\n",
       "      <td>0.855691</td>\n",
       "      <td>0.831707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(sampling, 1225.1355648040771), (loss, 5888.9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset     exp   algo            C  D      N  gamma      beta  \\\n",
       "0     ads  greedy  PBRFF  7224.677570  1  20000  0.001    10.000   \n",
       "1     ads  greedy  PBRFF   605.090164  1  20000  0.001     1.000   \n",
       "2     ads  greedy  PBRFF  5511.285799  1  20000  0.001     0.100   \n",
       "3     ads  greedy  PBRFF  9925.737610  1  20000  0.001     0.010   \n",
       "4     ads  greedy  PBRFF   837.124505  1  20000  0.001  1000.000   \n",
       "5     ads  greedy  PBRFF  8897.470010  1  20000  0.001     0.001   \n",
       "6     ads  greedy  PBRFF  2248.502085  1  20000  0.001   100.000   \n",
       "\n",
       "                    Loss_l                       E_l  nbrD_choisi  maxTry   p  \\\n",
       "0  [[0.22749169200972805]]   [0.0002386254153995136]            1       8  10   \n",
       "1  [[0.22841588234229918]]  [0.00026357920588288507]            1       9  11   \n",
       "2  [[0.22717899859508353]]  [3.8641050070245826e-05]            1       5   2   \n",
       "3    [[0.226902315669289]]   [0.0003386548842165355]            1       8  14   \n",
       "4  [[0.22067553325312386]]   [0.0002139662233373438]            1       8   9   \n",
       "5  [[0.22725865337578852]]  [0.00031363706733121056]            1       6  13   \n",
       "6  [[0.22067553325312386]]   [0.0002139662233373438]            1       3   9   \n",
       "\n",
       "    epsilon  train_error  val_error  test_error        f1  \\\n",
       "0  0.000006     0.126589   0.142276    0.167073  0.908728   \n",
       "1  0.000008     0.124555   0.144309    0.165854  0.909333   \n",
       "2  0.000001     0.127097   0.142276    0.164634  0.909940   \n",
       "3  0.000175     0.127097   0.144309    0.168293  0.908000   \n",
       "4  0.000040     0.872903   0.855691    0.831707  0.000000   \n",
       "5  0.000009     0.127097   0.144309    0.168293  0.908123   \n",
       "6  0.000021     0.872903   0.855691    0.831707  0.000000   \n",
       "\n",
       "                                                time  \n",
       "0  [(sampling, 1225.1355648040771), (loss, 5888.9...  \n",
       "1  [(sampling, 1225.1355648040771), (loss, 5888.9...  \n",
       "2  [(sampling, 1225.1355648040771), (loss, 5888.9...  \n",
       "3  [(sampling, 1225.1355648040771), (loss, 5888.9...  \n",
       "4  [(sampling, 1225.1355648040771), (loss, 5888.9...  \n",
       "5  [(sampling, 1225.1355648040771), (loss, 5888.9...  \n",
       "6  [(sampling, 1225.1355648040771), (loss, 5888.9...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = results_per_dataset[datasets[0]]\n",
    "r"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy Kernel Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in datasets:\n",
    "#     print(d)\n",
    "#     r = results_per_dataset[d]\n",
    "#     print(r)\n",
    "#     with open(\"/Users/jacobcomeau/Desktop/resultat_PBRFF_BASE_ADS.pkl\", 'wb') as out_file:\n",
    "#         pickle.dump(results, out_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n",
      "ads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n",
      "findfont: Font family 'normal' not found.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAGJCAYAAAAg1v9AAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtcElEQVR4nO3df3BU9b3/8deG4EIW94eEKAFMaBglJBeBAbVI9TYTJVmMqcQINBicZrw6vaS5kw5YZEC4rUbGeHUu13aiTpkAaYmTmNaW7Xhp0DreysDFxgZ3a8Yg0zjCZQy7CTNw1ySc7x9O93u3mwQOWeADPh8znxnOZz/nc94nrWdec/Zzzjosy7IEAACAKy7lShcAAACArxDMAAAADEEwAwAAMATBDAAAwBAEMwAAAEMQzAAAAAxBMAMAADDENR/MLMtSf3+/eF0bAAAw3TUfzE6fPi2Px6PTp09f6VIAAABGdc0HMwAAgKsFwQwAAMAQBDMAAABDEMwAAAAMQTADAAAwBMEMAADAEAQzAAAAQxDMAAAADEEwAwAAMATBDAAAwBAEMwAAAEMQzAAAAAxBMAMAADAEwQwAAMAQBDMAAABDEMwAAAAMQTADAAAwBMEMAADAEAQzAAAAQxDMAAAADEEwAwAAMATBDAAAwBAEMwAAAEMQzAAAAAxBMAMAADAEwQwAAMAQtoNZV1eXioqK5HK5lJGRoZqaGp09e/a8+zU3N6usrEzTpk2Tw+FQfX39iGM/+ugjPfDAA/J4PJo0aZIWLlyoP/7xj7HP33nnHTkcjoS2cuVKu6cDAABgjFQ7gyORiAoKCpSVlaXW1ladPHlStbW16u3t1e7du0fdt6WlRUePHlVJSYkaGhpGHPfnP/9Z3/rWt7Rs2TLt2bNHqamp+uCDD3TmzJmEsTt27NDs2bNj2+np6XZOBwAAwCi2gllDQ4PC4bA6OjpiISg1NVUVFRXauHGjcnNzR9y3ublZKSkpsXlG8sQTT2jZsmX6xS9+Eeu79957hx2bn5+vhQsX2jkFAAAAY9n6KjMQCKiwsDDuzlRZWZmcTqcCgcDoB0o5/6FCoZDef/99VVdX2ykLAADgmmArmIVCoYS7Yk6nUzk5OQqFQmMu5sCBA5Kkvr4+zZs3T6mpqcrOztb27duHHe/3+zVu3DhNnz5d69atG3WtW39/f1yLRqNjrhcAACCZbAWzcDgsr9eb0O/z+XTq1KkxF3PixAlJUkVFhVasWKF9+/bpwQcf1A9+8AM1NTXFxnk8Hq1fv147duzQvn379Oijj2r79u0qLy8fce4ZM2bI4/HEWl1d3ZjrBQAASCZba8wkyeFwJPRZljVsv13nzp2TJFVVVWnDhg2SpG9/+9vq7u7WM888o4qKCknS/PnzNX/+/Nh+BQUFmjp1qtauXauDBw/q9ttvT5i7p6dHbrc7tu10OsdcLwAAQDLZumPm8/kUDocT+iORiHw+35iLueGGGyR9FbT+r4KCAnV1dWlgYGDEfR9++GFJ0uHDh4f93O12xzWCGQAAMI2tYJabm5uwliwajaq7u3vUJzLtzD8cy7KUkpKSlLtyAAAAprIVzPx+v9rb29Xb2xvra2trUzQald/vH3Mxixcvls/n0+9///u4/vb2ds2ZM0epqSN/87pnzx5J0qJFi8ZcBwAAwJVga43Z448/ru3bt6u0tFSbNm2KvWC2oqIi7m5XVVWVGhsbNTg4GOsLBoMKBoOx7c7OTrW0tMjlcqm4uFiSdN1112nz5s1av369vF6v7rjjDv3mN7/R3r171dbWFtt39erVmjVrlhYsWKAJEyZo//79evHFF1VaWsp7zQAAwNXLsunjjz+27rvvPistLc1KT0+3qqurrTNnzsSNWbNmjfX3Uz/99NOWpISWlZWVcIyXXnrJmjlzpjV+/Hhr9uzZVmNjY9znzz77rJWXl2dNmjTJGj9+vHXLLbdYW7ZssaLRaMJcfX19liSrr6/P7qkCAABcVg7LsqwrmAsvuf7+fnk8HvX19cU9lQkAAGAa2z9iDgAAgEuDYAYAAGAIghkAAIAhCGYAAACGIJgBAAAYgmAGAABgCIIZAACAIQhmAAAAhiCYAQAAGIJgBgAAYAiCGQAAgCEIZgAAAIYgmAEAABiCYAYAAGAIghkAAIAhCGYAAACGIJgBAAAYgmAGAABgCIIZAACAIQhmAAAAhiCYAQAAGIJgBgAAYAiCGQAAgCEIZgAAAIYgmAEAABiCYAYAAGAIghkAAIAhbAezrq4uFRUVyeVyKSMjQzU1NTp79ux592tublZZWZmmTZsmh8Oh+vr6Ecd+9NFHeuCBB+TxeDRp0iQtXLhQf/zjH+PGnDhxQitWrJDb7ZbX61VlZaVOnTpl93QAAACMYSuYRSIRFRQU6PTp02ptbVV9fb2ampr02GOPnXfflpYWHT16VCUlJaOO+/Of/6zFixdr0qRJ2rNnj9ra2lReXq4zZ87ExgwODqqoqEidnZ3atWuXXnvtNb333nsqLS2VZVl2TgkAAMAYqXYGNzQ0KBwOq6OjQ+np6V9NkJqqiooKbdy4Ubm5uSPu29zcrJSUlNg8I3niiSe0bNky/eIXv4j13XvvvXFjWltb9eGHH+rIkSPKy8uTJGVmZuquu+7SW2+9paKiIjunBQAAYARbd8wCgYAKCwtjoUySysrK5HQ6FQgERj9QyvkPFQqF9P7776u6uvq8dcydOzcWyiRp8eLFys7O1t69e897HAAAABPZCmahUCjhrpjT6VROTo5CodCYizlw4IAkqa+vT/PmzVNqaqqys7O1ffv289YhSXPmzBmxjv7+/rgWjUbHXC8AAEAy2Qpm4XBYXq83od/n8yVl4f2JEyckSRUVFVqxYoX27dunBx98UD/4wQ/U1NQ0pjpmzJghj8cTa3V1dWOuFwAAIJlsrTGTJIfDkdBnWdaw/XadO3dOklRVVaUNGzZIkr797W+ru7tbzzzzjCoqKi66jp6eHrnd7ti20+kcc70AAADJZOuOmc/nUzgcTuiPRCLy+XxjLuaGG26QJBUUFMT1FxQUqKurSwMDAxddh9vtjmsEMwAAYBpbwSw3NzdhDVc0GlV3d/eoT2TamX84lmUpJSUldjdsuDokKRgMJqUOAACAK8FWMPP7/Wpvb1dvb2+sr62tTdFoVH6/f8zFLF68WD6fT7///e/j+tvb2zVnzhylpqbG6ujs7IwLZwcOHNCxY8e0bNmyMdcBAABwJdhaY/b4449r+/btKi0t1aZNm3Ty5EnV1taqoqIi7k5VVVWVGhsbNTg4GOsLBoMKBoOx7c7OTrW0tMjlcqm4uFiSdN1112nz5s1av369vF6v7rjjDv3mN7/R3r171dbWFtu3rKxMc+fO1UMPPaS6ujoNDg5q3bp1WrJkiZYuXXrRfwwAAIAryrLp448/tu677z4rLS3NSk9Pt6qrq60zZ87EjVmzZo3191M//fTTlqSElpWVlXCMl156yZo5c6Y1fvx4a/bs2VZjY2PCmM8//9wqLy+3rr/+esvtdlurV6+2vvjii4RxfX19liSrr6/P7qkCAABcVg7LurZ/w6i/v18ej0d9fX1xT2UCAACYxvaPmAMAAODSIJgBAAAYgmAGAABgCIIZAACAIQhmAAAAhiCYAQAAGIJgBgAAYAiCGQAAgCEIZgAAAIYgmAEAABiCYAYAAGAIghkAAIAhCGYAAACGIJgBAAAYgmAGAABgCIIZAACAIQhmAAAAhiCYAQAAGIJgBgAAYAiCGQAAgCEIZgAAAIYgmAEAABiCYAYAAGAIghkAAIAhCGYAAACGIJgBAAAYgmAGAABgCNvBrKurS0VFRXK5XMrIyFBNTY3Onj173v2am5tVVlamadOmyeFwqL6+fthxDocjod10001xY955551hx61cudLu6QAAABgj1c7gSCSigoICZWVlqbW1VSdPnlRtba16e3u1e/fuUfdtaWnR0aNHVVJSooaGhlHHVldX67vf/W5s+7rrrht23I4dOzR79uzYdnp6uo2zAQAAMIutYNbQ0KBwOKyOjo5YCEpNTVVFRYU2btyo3NzcEfdtbm5WSkpKbJ7R3HzzzbrzzjvPW09+fr4WLlxo4wwAAADMZeurzEAgoMLCwrg7U2VlZXI6nQoEAqMfKIXlbAAAAKOxlZZCoVDCXTGn06mcnByFQqGkFfXcc89p/Pjx8nq9WrFihf76178OO87v92vcuHGaPn261q1bN+pat/7+/rgWjUaTVi8AAEAy2PoqMxwOy+v1JvT7fD6dOnUqKQVVVlbq/vvv14033qgjR47oxz/+sZYsWaIPP/xQPp9PkuTxeLR+/Xrdfffdmjhxovbv36/6+nqFQiH99re/HXbeGTNmxG0//fTT2rJlS1JqBgAASAZbwUz66qnJv2dZ1rD9F6OxsTH277vvvltLlizRggUL9Oqrr2r9+vWSpPnz52v+/PmxcQUFBZo6darWrl2rgwcP6vbbb0+Yt6enR263O7btdDqTUi8AAECy2Poq0+fzKRwOJ/RHIpHY3axkmzt3rm699VYdPnx41HEPP/ywJI04zu12xzWCGQAAMI2tYJabm5uwliwajaq7u3vUJzLHyrKsSzY3AACAKWwFM7/fr/b2dvX29sb62traFI1G5ff7k16cJHV0dKirq0uLFi0addyePXsk6bzjAAAATOWwbNyOikQiys/PV3Z2tjZt2hR7wezSpUvjXjBbVVWlxsZGDQ4OxvqCwaCCwaAkqby8XJWVlSopKZHL5VJxcbEkqb6+XkePHtU999yjjIwMHTlyRM8884wmTpyoP/3pT7EHD1avXq1Zs2ZpwYIFmjBhgvbv368XX3xRxcXF+tWvfhVXc39/vzwej/r6+uLWmAEAAJjG1uJ/r9er/fv3q7q6WsuXL1daWppWrVqlbdu2xY0bGhrS0NBQXN/rr7+urVu3xrZ37typnTt3KisrS8eOHZMk3XrrrWptbdWePXt0+vRpTZkyRcuWLdNPfvKTuKdB8/Ly1NTUpBdeeEHRaFQzZ87UU089pQ0bNtg8fQAAAHPYumN2NeKOGQAAuFrwOn4AAABDEMwAAAAMQTADAAAwBMEMAADAEAQzAAAAQxDMAAAADEEwAwAAMATBDAAAwBAEMwAAAEMQzAAAAAxBMAMAADAEwQwAAMAQBDMAAABDEMwAAAAMQTADAAAwBMEMAADAEAQzAAAAQxDMAAAADEEwAwAAMATBDAAAwBAEMwAAAEMQzAAAAAxBMAMAADAEwQwAAMAQBDMAAABDEMwAAAAMYTuYdXV1qaioSC6XSxkZGaqpqdHZs2fPu19zc7PKyso0bdo0ORwO1dfXDzvO4XAktJtuuilh3IkTJ7RixQq53W55vV5VVlbq1KlTdk8HAADAGKl2BkciERUUFCgrK0utra06efKkamtr1dvbq927d4+6b0tLi44ePaqSkhI1NDSMOra6ulrf/e53Y9vXXXdd3OeDg4MqKirSl19+qV27dmlgYEDr169XaWmp3n33XTkcDjunBQAAYARbwayhoUHhcFgdHR1KT0//aoLUVFVUVGjjxo3Kzc0dcd/m5malpKTE5hnNzTffrDvvvHPEz1tbW/Xhhx/qyJEjysvLkyRlZmbqrrvu0ltvvaWioiI7pwUAAGAEW19lBgIBFRYWxkKZJJWVlcnpdCoQCIx+oJTkLWcLBAKaO3duLJRJ0uLFi5Wdna29e/cm7TgAAACXk620FAqFEu6KOZ1O5eTkKBQKJa2o5557TuPHj5fX69WKFSv017/+9bx1SNKcOXNGrKO/vz+uRaPRpNULAACQDLaCWTgcltfrTej3+XxJW3hfWVmpn/3sZ2pvb9ezzz6rd999V0uWLFE4HB5THTNmzJDH44m1urq6pNQLAACQLLbWmEkadmG9ZVlJW3Df2NgY+/fdd9+tJUuWaMGCBXr11Ve1fv36i66jp6dHbrc7tu10OpNSLwAAQLLYCmY+ny/uztXfRCKRURf+j8XcuXN166236vDhwxdUh8/nG3Yet9sdF8wAAABMY+urzNzc3IQ1XNFoVN3d3ZcsmElf3Qk7Xx2SFAwGL2kdAAAAl5KtYOb3+9Xe3q7e3t5YX1tbm6LRqPx+f9KLk6SOjg51dXVp0aJFcXV0dnbGhbMDBw7o2LFjWrZs2SWpAwAA4FJzWH9/O2oUkUhE+fn5ys7O1qZNm2IvmF26dGncC2arqqrU2NiowcHBWF8wGFQwGJQklZeXq7KyUiUlJXK5XCouLpYk1dfX6+jRo7rnnnuUkZGhI0eO6JlnntHEiRP1pz/9Kbbgf3BwUAsXLtTAwIDq6uo0ODiodevWKTMzM+EFs/39/fJ4POrr6+OrTAAAYDbLpo8//ti67777rLS0NCs9Pd2qrq62zpw5EzdmzZo11t9P/fTTT1uSElpWVlZszJtvvmndeeedls/ns1JTU62pU6da3/ve96zPP/88oY7PP//cKi8vt66//nrL7XZbq1evtr744ouEcX19fZYkq6+vz+6pAgAAXFa27phdjbhjBgAArhbJex0/AAAAxoRgBgAAYAiCGQAAgCEIZgAAAIYgmAEAABiCYAYAAGAIghkAAIAhCGYAAACGIJgBAAAYgmAGAABgCIIZAACAIQhmAAAAhiCYAQAAGIJgBgAAYAiCGQAAgCEIZgAAAIYgmAEAABiCYAYAAGAIghkAAIAhCGYAAACGIJgBAAAYgmAGAABgCIIZAACAIQhmAAAAhiCYAQAAGIJgBgAAYAiCGQAAgCFsB7Ouri4VFRXJ5XIpIyNDNTU1Onv27Hn3a25uVllZmaZNmyaHw6H6+vrz7lNTUyOHw6G1a9fG9b/zzjtyOBwJbeXKlXZPBwAAwBipdgZHIhEVFBQoKytLra2tOnnypGpra9Xb26vdu3ePum9LS4uOHj2qkpISNTQ0nPdYnZ2d+vnPfy632z3imB07dmj27Nmx7fT09As/GQAAAMPYCmYNDQ0Kh8Pq6OiIhaDU1FRVVFRo48aNys3NHXHf5uZmpaSkxOY5n7Vr16q2tlaNjY0jjsnPz9fChQvtnAIAAICxbH2VGQgEVFhYGHdnqqysTE6nU4FAYPQDpVz4oZqamvTpp5/qySeftFMeAADAVc1WMAuFQgl3xZxOp3JychQKhZJS0OnTp7Vu3To9//zzSktLG3Ws3+/XuHHjNH36dK1bt27UtW79/f1xLRqNJqVeAACAZLEVzMLhsLxeb0K/z+fTqVOnklLQli1bNGvWLK1YsWLEMR6PR+vXr9eOHTu0b98+Pfroo9q+fbvKy8tH3GfGjBnyeDyxVldXl5R6AQAAksXWGjNJcjgcCX2WZQ3bb1cwGNTLL7+sAwcOjDpu/vz5mj9/fmy7oKBAU6dO1dq1a3Xw4EHdfvvtCfv09PTEPUjgdDrHXC8AAEAy2bpj5vP5FA6HE/ojkYh8Pt+Yi6mtrVV5ebmys7MViUQUiUR07tw5ffnll7F/j+Thhx+WJB0+fHjYz91ud1wjmAEAANPYCma5ubkJa8mi0ai6u7tHfSLzQv3lL3/R7t275fP5Yq2np0evvvqqfD6furq6xnwMAAAAU9n6KtPv9+vHP/6xent7NXnyZElSW1ubotGo/H7/mIvZs2eP/vd//zeub+XKlfrmN7+pmpoa3XzzzaPuK0mLFi0acx0AAABXgq1g9vjjj2v79u0qLS3Vpk2bYi+YraioiLtjVlVVpcbGRg0ODsb6gsGggsFgbLuzs1MtLS1yuVwqLi6WJN15550Jx5wwYYKmTZumf/zHf4z1rV69WrNmzdKCBQs0YcIE7d+/Xy+++KJKS0t5rxkAALhq2QpmXq9X+/fvV3V1tZYvX660tDStWrVK27Ztixs3NDSkoaGhuL7XX39dW7dujW3v3LlTO3fuVFZWlo4dO2ar6Ly8PDU1NemFF15QNBrVzJkz9dRTT2nDhg225gEAADCJw7Is60oXcSn19/fL4/Gor69v1J93AgAAuNJs/4g5AAAALg2CGQAAgCEIZgAAAIYgmAEAABiCYAYAAGAIghkAAIAhCGYAAACGIJgBAAAYgmAGAABgCIIZAACAIQhmAAAAhiCYAQAAGIJgBgAAYAiCGQAAgCEIZgAAAIYgmAEAABiCYAYAAGAIghkAAIAhCGYAAACGIJgBAAAYgmAGAABgCIIZAACAIQhmAAAAhiCYAQAAGIJgBgAAYAiCGQAAgCFsB7Ouri4VFRXJ5XIpIyNDNTU1Onv27Hn3a25uVllZmaZNmyaHw6H6+vrz7lNTUyOHw6G1a9cmfHbixAmtWLFCbrdbXq9XlZWVOnXqlN3TAQAAMIatYBaJRFRQUKDTp0+rtbVV9fX1ampq0mOPPXbefVtaWnT06FGVlJRc0LE6Ozv185//XG63O+GzwcFBFRUVqbOzU7t27dJrr72m9957T6WlpbIsy84pAQAAGCPVzuCGhgaFw2F1dHQoPT39qwlSU1VRUaGNGzcqNzd3xH2bm5uVkpISm+d81q5dq9raWjU2NiZ81traqg8//FBHjhxRXl6eJCkzM1N33XWX3nrrLRUVFdk5LQAAACPYumMWCARUWFgYC2WSVFZWJqfTqUAgMPqBUi78UE1NTfr000/15JNPjljH3LlzY6FMkhYvXqzs7Gzt3bv3go8DAABgElvBLBQKJdwVczqdysnJUSgUSkpBp0+f1rp16/T8888rLS3tguuQpDlz5oxYR39/f1yLRqNJqRcAACBZbAWzcDgsr9eb0O/z+ZK28H7Lli2aNWuWVqxYkdQ6ZsyYIY/HE2t1dXVJqRcAACBZbK0xkySHw5HQZ1nWsP12BYNBvfzyyzpw4EDS6+jp6Yl7kMDpdF58oQAAAJeArWDm8/kUDocT+iORyKgL/y9UbW2tysvLlZ2drUgkIkk6d+6cvvzyS0UiEbndbqWkpIxah8/nG3Zut9s97BOeAAAAprD1VWZubm7CGq5oNKru7u6kBLO//OUv2r17t3w+X6z19PTo1Vdflc/nU1dX14h1SF/dcUtGHQAAAFeCrWDm9/vV3t6u3t7eWF9bW5ui0aj8fv+Yi9mzZ4/efvvtuHbjjTfqO9/5jt5++23dfPPNsTo6OzvjwtmBAwd07NgxLVu2bMx1AAAAXAkOy8YbWSORiPLz85Wdna1Nmzbp5MmTqq2t1dKlS7V79+7YuKqqKjU2NmpwcDDWFwwGFQwGJUnl5eWqrKxUSUmJXC6XiouLRzxmdna27r//fv3Hf/xHrG9wcFALFy7UwMCA6urqNDg4qHXr1ikzM1Pvvvtu3Dqz/v5+eTwe9fX18VUmAAAwmq01Zl6vV/v371d1dbWWL1+utLQ0rVq1Stu2bYsbNzQ0pKGhobi+119/XVu3bo1t79y5Uzt37lRWVpaOHTtmr+jUVP3ud79TTU2NVq9eLYfDoQceeEAvvfRSUh5CAAAAuBJs3TG7GnHHDAAAXC1s/4g5AAAALg2CGQAAgCEIZgAAAIYgmAEAABiCYAYAAGAIghkAAIAhCGYAAACGIJgBAAAYgmAGAABgCIIZAACAIQhmAAAAhiCYAQAAGIJgBgAAYAiCGQAAgCEIZgAAAIYgmAEAABiCYAYAAGAIghkAAIAhCGYAAACGIJgBAAAYgmAGAABgCIIZAACAIQhmAAAAhiCYAQAAGIJgBgAAYAiCGQAAgCEIZgAAAIawHcy6urpUVFQkl8uljIwM1dTU6OzZs+fdr7m5WWVlZZo2bZocDofq6+sTxpw+fVoPPfSQZs6cqYkTJ2rKlCkqLi7WoUOH4sa98847cjgcCW3lypV2TwcAAMAYqXYGRyIRFRQUKCsrS62trTp58qRqa2vV29ur3bt3j7pvS0uLjh49qpKSEjU0NAw75ssvv9TEiRO1ZcsW3XzzzYpEInrppZdUUFCgw4cP65Zbbokbv2PHDs2ePTu2nZ6ebud0AAAAjGIrmDU0NCgcDqujoyMWglJTU1VRUaGNGzcqNzd3xH2bm5uVkpISm2c4kydP1q5du+L67r33Xk2ePFktLS166qmn4j7Lz8/XwoUL7ZwCAACAsWx9lRkIBFRYWBh3Z6qsrExOp1OBQGD0A6Vc3HI2l8ulCRMmaGBg4KL2BwAAuFrYSkuhUCjhrpjT6VROTo5CoVDSijp37pwGBwd1/Phx/fCHP1RKSooeeeSRhHF+v1/jxo3T9OnTtW7dulHXuvX398e1aDSatHoBAACSwVYwC4fD8nq9Cf0+n0+nTp1KVk3avHmzxo8fr8zMTDU1NSkQCOgb3/hG7HOPx6P169drx44d2rdvnx599FFt375d5eXlI845Y8YMeTyeWKurq0tavQAAAMlga42ZJDkcjoQ+y7KG7b9Y3//+9/Wd73xHx48f1yuvvCK/36/29nYtWLBAkjR//nzNnz8/Nr6goEBTp07V2rVrdfDgQd1+++0Jc/b09Mjtdse2nU5n0uoFAABIBlt3zHw+n8LhcEJ/JBKRz+dLWlGZmZlauHChSkpK9Otf/1pZWVnavHnzqPs8/PDDkqTDhw8P+7nb7Y5rBDMAAGAaW8EsNzc3YS1ZNBpVd3f3qE9kjkVKSormzZunTz755JLMDwAAYApbwexvXyn29vbG+tra2hSNRuX3+5NenCQNDAzo4MGDcWvMhrNnzx5J0qJFiy5JHQAAAJearTVmjz/+uLZv367S0lJt2rQp9oLZioqKuDtmVVVVamxs1ODgYKwvGAwqGAzGtjs7O9XS0iKXy6Xi4mJJ0iuvvKKDBw+qsLBQU6dO1fHjx9XQ0KBPPvkk7t1nq1ev1qxZs7RgwQJNmDBB+/fv14svvqjS0lLeawYAAK5atoKZ1+vV/v37VV1dreXLlystLU2rVq3Stm3b4sYNDQ1paGgoru/111/X1q1bY9s7d+7Uzp07lZWVpWPHjkmS8vLy9MYbb6impkaRSEQ33XSTFi1apEOHDum2226L7ZuXl6empia98MILikajmjlzpp566ilt2LDB7vkDAAAYw2FZlnWli7iU+vv75fF41NfXF/dUJgAAgGku7nX8AAAASDqCGQAAgCEIZgAAAIYgmAEAABiCYAYAAGAIghkAAIAhCGYAAACGIJgBAAAYgmAGAABgCIIZAACAIQhmAAAAhiCYAQAAGIJgBgAAYAiCGQAAgCEIZgAAAIYgmAEAABiCYAYAAGAIghkAAIAhCGYAAACGIJgBAAAYgmAGAABgCIIZAACAIQhmAAAAhiCYAQAAGIJgBgAAYAiCGQAAgCFsB7Ouri4VFRXJ5XIpIyNDNTU1Onv27Hn3a25uVllZmaZNmyaHw6H6+vqEMadPn9ZDDz2kmTNnauLEiZoyZYqKi4t16NChhLEnTpzQihUr5Ha75fV6VVlZqVOnTtk9HQAAAGPYCmaRSEQFBQU6ffq0WltbVV9fr6amJj322GPn3belpUVHjx5VSUnJiGO+/PJLTZw4UVu2bFEgENArr7yiM2fOqKCgQF1dXbFxg4ODKioqUmdnp3bt2qXXXntN7733nkpLS2VZlp1TAgAAMEaqncENDQ0Kh8Pq6OhQenr6VxOkpqqiokIbN25Ubm7uiPs2NzcrJSUlNs9wJk+erF27dsX13XvvvZo8ebJaWlr01FNPSZJaW1v14Ycf6siRI8rLy5MkZWZm6q677tJbb72loqIiO6cFAABgBFt3zAKBgAoLC2OhTJLKysrkdDoVCARGP1DKxS1nc7lcmjBhggYGBuLqmDt3biyUSdLixYuVnZ2tvXv3XtRxAAAArjRbaSkUCiXcFXM6ncrJyVEoFEpaUefOndPg4KCOHz+uH/7wh0pJSdEjjzwyah2SNGfOnKTWAQAAcDnZCmbhcFherzeh3+fzJXXh/ebNmzV+/HhlZmaqqalJgUBA3/jGN8ZUR39/f1yLRqNJqxcAACAZbH+/6HA4Evosyxq2/2J9//vf16FDh/Tmm2/q9ttvl9/v1wcffDCmOmbMmCGPxxNrdXV1SasXAAAgGWwt/vf5fAqHwwn9kUhk1IX/dmVmZiozM1OStGzZMi1YsECbN2/Wb3/72/PW4fP5hp2zp6dHbrc7tu10OpNWLwAAQDLYumOWm5ubsIYrGo2qu7s7qcHs/0pJSdG8efP0ySefjFqHJAWDwRHrcLvdcY1gBgAATGMrmPn9frW3t6u3tzfW19bWpmg0Kr/fn/TiJGlgYEAHDx6MW2Pm9/vV2dkZF84OHDigY8eOadmyZZekDgAAgEvNYdl4I2skElF+fr6ys7O1adMmnTx5UrW1tVq6dKl2794dG1dVVaXGxkYNDg7G+oLBoILBoCSpvLxclZWVKikpkcvlUnFxsSTplVde0cGDB1VYWKipU6fq+PHjamho0H/913+pvb1d3/rWtyR99YLZhQsXamBgQHV1dRocHNS6deuUmZmpd999N26dWX9/vzwej/r6+uK+ygQAADCNrTVmXq9X+/fvV3V1tZYvX660tDStWrVK27Ztixs3NDSkoaGhuL7XX39dW7dujW3v3LlTO3fuVFZWlo4dOyZJysvL0xtvvKGamhpFIhHddNNNWrRokQ4dOqTbbrvt/xedmqrf/e53qqmp0erVq+VwOPTAAw/opZdeSupDCAAAAJeTrTtmVyPumAEAgKvFxb2OHwAAAElHMAMAADAEwQwAAMAQBDMAAABDEMwAAAAMQTADAAAwBMEMAADAEAQzAAAAQxDMAAAADEEwAwAAMATBDAAAwBAEMwAAAEMQzAAAAAxBMAMAADAEwQwAAMAQBDMAAABDEMwAAAAMQTADAAAwBMEMAADAEAQzAAAAQxDMAAAADEEwAwAAMATBDAAAwBAEMwAAAEMQzAAAAAxBMAMAADAEwQwAAMAQtoNZV1eXioqK5HK5lJGRoZqaGp09e/a8+zU3N6usrEzTpk2Tw+FQfX39sHNXV1drzpw5crlcysrKUlVVlU6cOBE37p133pHD4UhoK1eutHs6AAAAxki1MzgSiaigoEBZWVlqbW3VyZMnVVtbq97eXu3evXvUfVtaWnT06FGVlJSooaFh2DH/+Z//qT/84Q/6p3/6J82bN0+fffaZtmzZom9+85vq7OzUpEmT4sbv2LFDs2fPjm2np6fbOR0AAACj2ApmDQ0NCofD6ujoiIWg1NRUVVRUaOPGjcrNzR1x3+bmZqWkpMTmGc7KlSv1z//8z3I4HLG+uXPn6rbbblNra6vWrFkTNz4/P18LFy60cwoAAADGsvVVZiAQUGFhYdydqbKyMjmdTgUCgdEPlHL+Q6Wnp8eFMkn6h3/4B40bN06ff/65nVIBAACuOraCWSgUSrgr5nQ6lZOTo1AolNTC/ub999/X0NDQsHfj/H6/xo0bp+nTp2vdunXDrnWLRqOSpC+++EL9/f2x9rd+AJC+ulZs2bKFawOAUV3qa4WtYBYOh+X1ehP6fT6fTp06layaYgYGBvQv//IvuvXWW3X//ffH+j0ej9avX68dO3Zo3759evTRR7V9+3aVl5cnzPG3P1xOTo48Hk+s1dXVJb1eAFevaDSqrVu3EswAjOpSXytsP5X59181SpJlWcP2j9XatWt15MgR7d69W6mp/3853Pz587Vt2zYtW7ZMBQUF+slPfqIXXnhBe/fu1cGDB4edKxgMqq+vL9Y2bNiQ9HqvVS+//PKVLuGimVD75arhUh0nGfOOdY6L3d+E//2/Tq7mv7cptV/N14tkzTmWea6Ja4Vlw5QpU6wnn3wyoX/OnDlWVVXVBc8jyXr++edHHbNlyxZr3Lhx1q9//esLmvPkyZOWJOunP/1pXH9PT48lyerp6bng+hAvNzf3Spdw0Uyo/XLVcKmOk4x5xzrHxe5vZ7++vj5LktXX13dRx4IZ/71dLFNqv5qvF8macyzzXAvXCltPZebm5iasJYtGo+ru7tb3vve9ZGVF/fSnP9WWLVvU0NCgBx54YExzWZYlSTp9+rT6+/uTUd7XztDQ0FX7tzOh9stVw6U6TjLmHescF7u/nf3+Nu5K///lambCf28Xy5Tar+brRbLmHMs8l/Na8bd8kXR2Utxzzz1nuVwu64svvoj1/fKXv7QkWcFg8ILn0Sh3zH75y19aKSkp1r/+67/aKc3693//d0uSdejQobj+7u5uSxKNRqPRaDRa0trJkydt5ZQL5bCsC498kUhE+fn5ys7O1qZNm2IvmF26dGncC2arqqrU2NiowcHBWF8wGFQwGJQklZeXq7KyUiUlJXK5XCouLpYk/eEPf9C9996rxYsX67nnnos79pQpU5STkyNJWr16tWbNmqUFCxZowoQJ2r9/v1588UUVFxfrV7/6Vdx+586d0+eff67rr7/+kqyDAwAAXz+XLFfYTXIff/yxdd9991lpaWlWenq6VV1dbZ05cyZuzJo1a6y/n/rpp58eNnFmZWWdd4wka82aNbFxzz77rJWXl2dNmjTJGj9+vHXLLbdYW7ZssaLRqN3TAQAAMIatO2YAAAC4dGy/LuProKqqKvZj6//361gAX1+hUEiLFi3SLbfcooKCAh0/fvxKlwTAQGPNEASzYVRWVuqDDz640mUAMMgTTzyhH/3oR+rq6tKyZcv0ox/96EqXBMBAY80QV0Uw++STT/TEE09o3rx5Sk1NVX5+/rDjurq6VFRUJJfLpYyMDNXU1Az7M03nc8899+jGG28ca9kArrBkXTv+53/+R6FQSMuXL5ckPfbYY3rjjTcuyzkAuPSSmTPGmiFsvcfsSvnoo4+0d+9e3XHHHTp37pzOnTuXMCYSiaigoEBZWVlqbW2NPTHa29sb98QogK+PZF07PvvsM82YMSP2BJbb7db48ePV29uryZMnX9ZzApB8JuWMqyKYlZSUqLS0VJL06KOP6r//+78TxjQ0NCgcDqujo0Pp6emSpNTUVFVUVGjjxo2xH0FfsmSJPvvss4T958yZo0AgcAnPAsDllqxrx0jPSPEKHuDakMycMVZXxVeZKSnnLzMQCKiwsDD2x5KksrIyOZ3OuMD13nvv6dixYwmNUAZce5J17ZgxY4Y+++yzuF8SGRgY0A033HBpCgdwWSUzZ4y5lqTNdIWFQqGEtOp0OpWTk5PwM1IA8DcXcu248cYbdeutt8ZeYP3aa6/pwQcfvNylAriCLlfOuGaCWTgcltfrTej3+Xw6deqUrbkeeeQRTZ8+XZKUnZ2tVatWJaNEAAa60GvHz372Mz3zzDO65ZZb9Oabbyb8OgmAa9uFXivGmiGuijVmF2q49R6WZdleB7Jr165klQTgKnAh1468vLxh150A+Pq4kGvFWDPENXPHzOfzKRwOJ/RHIhH5fL4rUBGAqwHXDgAX4nJdK66ZYJabm5vwHW80GlV3d3fSnpQAcO3h2gHgQlyua8U1E8z8fr/a29vV29sb62tra1M0GpXf77+ClQEwGdcOABficl0rroofMT9z5kzsUdSXX35Z3d3d+rd/+zdJX71hd8qUKYpEIsrPz1d2drY2bdoUe/Hb0qVLecEs8DXFtQPAhTDqWmFdBT799FNL0rDt7bffjo37+OOPrfvuu89KS0uz0tPTrerqauvMmTNXrnAAVxTXDgAXwqRrxVVxxwwAAODr4JpZYwYAAHC1I5gBAAAYgmAGAABgCIIZAACAIQhmAAAAhiCYAQAAGIJgBgAAYAiCGQAAgCEIZgAAAIYgmAEAABiCYAYAAGAIghkAAIAh/h8c6ebh1Ca2ZgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 20000\n",
    "max_D = 5000\n",
    "\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (6, 4)\n",
    "for d in datasets:\n",
    "    print(d)\n",
    "    r = results_per_dataset[d]\n",
    "\n",
    "    # # SVM\n",
    "    # svm_error = list(r.loc[r.algo == 'SVM']['test_error'])[0]\n",
    "    # plt.axhline(y=svm_error, color='r', linestyle='-', linewidth=1, label=\"SVM RBF\")\n",
    "\n",
    "    # # RFF\n",
    "    # r_rff = r.loc[r.algo == 'RFF'].loc[r.D <= max_D].set_index('D')\n",
    "    # plt.semilogx(r_rff['train_error'], \"--\", label=f\"RFF-train\",color ='g', linewidth=0.9, alpha=0.4)\n",
    "    # plt.semilogx(r_rff['test_error'], \"-\", label=f\"RFF-test\", color ='g', linewidth=1.1)\n",
    "    \n",
    "    # # Optimized Kernel RFF\n",
    "    # r_okrff = r.loc[r.algo == 'OKRFF'].loc[r.D <= max_D]\n",
    "    # r_okrff = r.loc[r_okrff.groupby(['D'])[\"val_error\"].idxmin()].set_index('D')\n",
    "    # plt.semilogx(r_okrff['train_error'], \"--\", label=f\"OKRFF-train\", color ='y', linewidth=0.9,alpha=0.4)\n",
    "    # plt.semilogx(r_okrff['test_error'], \"-\", label=f\"OKRFF-test\", color ='y', linewidth=1)\n",
    "    \n",
    "    # PAC-Bayes RFF\n",
    "    r_pbrff = r.loc[r.algo == 'PBRFF'].loc[r.D <= max_D].sort_values('beta', ascending=False)\n",
    "    r_pbrff = r.loc[r_pbrff.groupby(['D'])[\"val_error\"].idxmin()].set_index('D')\n",
    "    plt.semilogx(r_pbrff['train_error'], \"--\", label=f\"PBRFF-train\", color ='b', linewidth=0.9,alpha=0.4)\n",
    "    plt.semilogx(r_pbrff['test_error'], \"-\", label=f\"PBRFF-test\", color ='b', linewidth=1)\n",
    "    \n",
    "    sns.despine(top=True, right=True)\n",
    "    if d in [\"mnist49\", \"mnist17\"]:\n",
    "        leg = plt.legend(frameon=True, fontsize='x-large')\n",
    "        leg_lines = leg.get_lines()\n",
    "        plt.setp(leg_lines, linewidth=1.3)\n",
    "    plt.tight_layout()\n",
    "    plt.autoscale(enable=True, axis='x', tight=True)\n",
    "    tick_params(axis='both', which='both', pad=2, direction='in', labelsize=11)\n",
    "    plt.savefig(join(output_path, f\"error_vs_features_{d}.pdf\"))\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landmarks-Based Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Test error of the landmarks-based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# landmarks_method = 'clustering'\n",
    "# perc_landmarks = 0.1\n",
    "# beta = 1\n",
    "# D = 64\n",
    "\n",
    "# ### SVM ###\n",
    "# svm_results = pd.DataFrame(results.loc[results.algo == 'SVM'].set_index('dataset')['test_error'])\\\n",
    "#                                                              .rename(columns={'test_error': 'svm'})\n",
    "\n",
    "# ### RBF ###\n",
    "# rbf_results = pd.DataFrame(results.loc[(results.algo == 'RBF') & \\\n",
    "#                                        (results.perc_landmarks == perc_landmarks) & \\\n",
    "#                                        (results.method == landmarks_method)] \\\n",
    "#                                        .set_index('dataset')['test_error']) \\\n",
    "#                                        .rename(columns={'test_error': 'rbf'})\n",
    "\n",
    "# ### PAC-Bayes ###\n",
    "# pb_results = results.loc[(results.algo == 'PB') & (results.perc_landmarks == perc_landmarks) & \\\n",
    "#                          (results.method == landmarks_method)].sort_values('beta', ascending=True)\n",
    "\n",
    "# # beta and D optimized on validation set\n",
    "\n",
    "# pb_results_optimized = pd.DataFrame(pb_results.loc[pb_results.groupby(['method', 'perc_landmarks', 'dataset']) \\\n",
    "#                                                   [\"val_error\"].idxmin()].set_index('dataset')['test_error']) \\\n",
    "#                                                   .rename(columns={'test_error': 'pb'})\n",
    "\n",
    "# # beta fixed, D optimized on validation set\n",
    "# pb_results_beta = pb_results.loc[pb_results.beta == beta]\n",
    "# pb_results_beta = pd.DataFrame(pb_results_beta.loc[pb_results_beta.groupby(['method', 'perc_landmarks', 'dataset']) \\\n",
    "#                                                   [\"val_error\"].idxmin()].set_index('dataset')['test_error'])\\\n",
    "#                                                   .rename(columns={'test_error': 'pb_beta'})\n",
    "\n",
    "# # beta optimized on validation set, D fixed\n",
    "# pb_results_D = pb_results.loc[pb_results.D == D]\n",
    "# pb_results_D = pd.DataFrame(pb_results_D.loc[pb_results_D.groupby(['method', 'perc_landmarks', 'dataset']) \\\n",
    "#                                             [\"val_error\"].idxmin()].set_index('dataset')['test_error']) \\\n",
    "#                                             .rename(columns={'test_error': 'pb_D'})\n",
    "\n",
    "\n",
    "# table = svm_results.join(rbf_results).join(pb_results_optimized).join(pb_results_beta).join(pb_results_D)\n",
    "# table = (100*table).round(2).sort_index()\n",
    "# print(table.to_latex())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Behavior of the Landmarks-based approach according to the percentage of training points selected as landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pylab inline\n",
    "# pylab.rcParams['figure.figsize'] = (7, 5)\n",
    "# for d in datasets:\n",
    "#     print(f\"Dataset: {d}\")\n",
    "#     r = results_per_dataset[d]\n",
    "    \n",
    "#     ### SVM ###\n",
    "#     svm_error = list(r.loc[r.algo == 'SVM']['test_error'])[0]\n",
    "#     plt.axhline(y=svm_error, color='r', linestyle='-', linewidth=1.2, label=\"SVM RBF\")\n",
    "    \n",
    "#     ### RBF ###\n",
    "#     r_rbf = r.loc[r.algo == 'RBF'].sort_values('perc_landmarks')\n",
    "#     for method in r_rbf.method.unique():\n",
    "#         plt.plot(r_rbf.loc[r_rbf.method == method].set_index(['perc_landmarks'])['test_error'], \n",
    "#                  '--' if method == \"random\" else \"-\", \n",
    "#                  label=f\"RBF Landmarks\" + (\"-R\" if method == \"random\" else \"-C\"),\n",
    "#                  color = 'g',\n",
    "#                  linewidth=1)\n",
    "        \n",
    "#     ### PAC-Bayes ###\n",
    "#     r_pb = r.loc[r.algo == 'PB'].sort_values('perc_landmarks', ascending=False).sort_values('beta', ascending=True)\n",
    "\n",
    "#     # Selecting beta and D based on error on the validation set\n",
    "#     r_pb = r_pb.loc[r_pb.groupby(['method', 'perc_landmarks'])[\"val_error\"].idxmin()]\n",
    "#     for method in r_pb.method.unique():\n",
    "#         plt.plot(r_pb.loc[r_pb.method == method].set_index(['perc_landmarks'])['test_error'], \n",
    "#                  '--' if method == \"random\" else \"-\", \n",
    "#                  label=f\"PB Landmarks\"  + (\"-R\" if method == \"random\" else \"-C\"),\n",
    "#                  color = 'b',\n",
    "#                  linewidth = 1)\n",
    "\n",
    "#     plt.xlabel(\"Percentage of landmarks\", fontsize=14)\n",
    "#     plt.ylabel(\"Misclassification error\", fontsize=14)\n",
    "#     sns.despine(top=True, right=True)\n",
    "#     plt.tight_layout()\n",
    "#     plt.autoscale(enable=True, axis='x', tight=True)\n",
    "#     plt.tick_params(axis='both', which='both', pad=3, direction='out', labelsize=12)\n",
    "#     if d == \"farm\":\n",
    "#         plt.legend(frameon=True, fontsize='large')\n",
    "#     elif d == \"ads\":\n",
    "#         plt.legend(frameon=True, fontsize='large',loc=(0.64, 0.32))\n",
    "#     plt.savefig(join(output_path, f\"error_landmarks_{d}.pdf\"))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
